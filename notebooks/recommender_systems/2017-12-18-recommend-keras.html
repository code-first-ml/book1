
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Recommender Systems in Keras &#8212; Prog-ML</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script kind="utterances">

    var commentsRunWhenDOMLoaded = cb => {
    if (document.readyState != 'loading') {
        cb()
    } else if (document.addEventListener) {
        document.addEventListener('DOMContentLoaded', cb)
    } else {
        document.attachEvent('onreadystatechange', function() {
        if (document.readyState == 'complete') cb()
        })
    }
}

var addUtterances = () => {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src = "https://utteranc.es/client.js";
    script.async = "async";

    script.setAttribute("repo", "prog-ml/prog-ml.github.io");
    script.setAttribute("issue-term", "pathname");
    script.setAttribute("theme", "github-light");
    script.setAttribute("label", "ðŸ’¬ comment");
    script.setAttribute("crossorigin", "anonymous");

    sections = document.querySelectorAll("div.section");
    if (sections !== null) {
        section = sections[sections.length-1];
        section.appendChild(script);
    }
}
commentsRunWhenDOMLoaded(addUtterances);
</script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Neural Networks for Collaborative Filtering" href="2017-12-29-neural-collaborative-filtering.html" />
    <link rel="prev" title="Programatically understanding Expectation Maximization" href="../em/2014-06-01-em.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/prog-ml.jpg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Prog-ML</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../intro.html">
   Prog-ML
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../introduction/mle_coin.html">
   MLE, MAP and Fully Bayesian (conjugate prior and MCMC) for coin toss
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../introduction/variational.html">
   Variational Inference from scratch in JAX
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Probability Basics
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../probability/sample-space.html">
   Sample Space
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../probability/random-variable.html">
   Random Variables
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../probability/pmf.html">
   Probability Mass Function (PMF)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Continuous Probability Distributions
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../probability/univariate-normal.html">
   Properties of RV
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../probability/univariate-normal-expectations.html">
   Derivations for moments of univariate normal distribution
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../probability/mvn-introduction.html">
   Multivariate Normal Distribution: Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../probability/mvn-marginal.html">
   Multivariate Normal Distribution: Marginals
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Bayesian ML
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../bayesian_ml/2021-03-23-bayesian-ml.html">
   Bayesian ML: Fundamentals
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../bayesian_ml/2021-04-14-bayesian-linear-regression.html">
   Bayesian linear regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../bayesian_ml/2021-03-29-bayesian-model-selection.html">
   Bayesian model selection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../bayesian_ml/2021-03-27-Marginal-Likelihood-2.html">
   Marginal likelihood
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../bayesian_ml/2021-03-31-derivation-of-marginal-likelihood.html">
   Marginal likelihood for Bayesian linear regression
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Sampling from Distributions
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../sampling/rejection-sampling-lr.html">
   Simple rejection sampling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../sampling/Metropolis-Hastings.html">
   Metropolis Hastings
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../sampling/2021-03-10-importance-sampling.html">
   Importance sampling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../sampling/2021-03-10-rejection-sampling.html">
   Rejection sampling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../sampling/2022-02-04-sampling-normal.html">
   Sampling from univariate and multivariate normal distributions using Box-Muller transform
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../sampling/2020-04-16-inverse-transform.html">
   Sampling from common distributions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../sampling/2014-05-01-gibbs-sampling.html">
   Gibbs sampling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../sampling/2014-07-01-mcmc_coins.html">
   Coin tosses and MCMC
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Graphical Models
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../graphical_models/2022-02-15-draw-graphical-models.html">
   Drawing graphical models
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Mixture Models
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../mixture_models/2022-02-14-GMM.html">
   GMM learning
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Information Theory
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../information_theory/kl-divergence.html">
   Understanding KL-Divergence
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Variational Models
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../variational_models/2022-02-12-variational-inference.html">
   Variational Inference
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Bayesian ML with PyMC
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../bayesian_ml_with_pymc/2021-03-11-blr-pymc.html">
   Bayesian linear regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../bayesian_ml_with_pymc/2021-03-12-logistic-bayesian.html">
   Bayesian logistic regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../gaussian_processes/2021-03-16-GP-PyMC3.html">
   Gaussian process regression in PyMC
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../gaussian_processes/2021-03-17-lls-gp-pymc3.html">
   Local Lengthscale GP with PyMC
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Bayesian ML with Pyro
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../bayesian_ml_with_pyro/2021-08-20-Bayesian.html">
   Probabilistic Programming in Pyro
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../bayesian_ml_with_pyro/2022_02_17_pyro_linreg.html">
   Linear Regression using Pyro
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../bayesian_ml_with_pyro/2022-02-20-condition-pyro.html">
   Pyro Conditioning
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Bayesian ML with PyTorch
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../bayesian_ml_with_pytorch/2022-02-09-pytorch-learn-normal.html">
   Maximum Likelihood Estimation (MLE) for parameters of univariate and multivariate normal distribution in PyTorch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../bayesian_ml_with_pytorch/2022-02-11-pytorch-learn-normal-map.html">
   Maximum A-Posteriori (MAP) for parameters of univariate and multivariate normal distribution in PyTorch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../bayesian_ml_with_pytorch/2022-02-17-ppca.html">
   Probabilstic PCA using PyTorch distributions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../bayesian_ml_with_pytorch/2022-02-14-logistic-regression.html">
   Logistic Regression using PyTorch distributions
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Bayesian ML with Tensorflow Probability
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../bayesian_ml_with_tfp/2022-01-26-tfp-distributions.html">
   Testing out some distributions in Tensorflow Probability
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../bayesian_ml_with_tfp/2022-02-07-coin-toss.html">
   Coin Toss (MLE, MAP, Fully Bayesian) in TF Probability
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../bayesian_ml_with_tfp/2022-01-28-tfp-linear-regression.html">
   Linear Regression in Tensorflow Probability
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../bayesian_ml_with_tfp/2022-02-05-lr.html">
   Linear Regression in TF Probability using JointDistributionCoroutineAutoBatched
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../bayesian_ml_with_tfp/2022-02-05-simple-dgm.html">
   Simple Directed Graphical Models in TF Probability
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Bayesian ML with Julia
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../bayesian_ml_with_julia/2021-09-01-Hello-Julia-Language.html">
   Linear Regression from scratch in Julia
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Gaussian Processes
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../gaussian_processes/2020-03-26-gp.html">
   Some experiments in Gaussian Processes Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../gaussian_processes/2021-04-15-LLS-GP.html">
   Local Lengthscale GP
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../gaussian_processes/2021-04-15-deep-gp-from-scratch.html">
   Deep Kernel Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../gaussian_processes/2021-04-16-ard-gp.html">
   Automatic relevance determination (ARD)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../gaussian_processes/2021-04-16-GP-vs-DeepGP.html">
   GP v/s Deep GP on 2d data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../gaussian_processes/2022-02-23-gp_rff.html">
   Gaussian Processes with Random Fourier Features
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../gaussian_processes/2020-03-29-param-learning.html">
   Learning Gaussian Process regression parameters using gradient descent
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../gaussian_processes/2021-09-03-param-learning-sgd.html">
   Learning Gaussian Process regression parameters using mini-batch stochastic gradient descent
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../gaussian_processes/2020-06-26-gp-understand.html">
   Understanding Kernels in Gaussian Processes Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../gaussian_processes/pyro-deep-gp.html">
   Deep Kernel Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../gaussian_processes/pyro-binary-classification.html">
   GP Classification
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Linear Regression
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../linear_regression/2022_02_21_coordinate_descent_failure.html">
   Coordinate descent failure example
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Generative Adversarial Networks
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../gans/2021-05-31-GAN.html">
   A programming introduction to GANs
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Hidden Markov Models
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../hmms/2013-06-01-hmm_simulate.html">
   HMM Simulation for Unfair Casino Problem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../hmms/2013-07-01-hmm_continuous.html">
   HMM Simulation for Continuous HMM
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tensor Factorization
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../tensor_factorization/2017-04-19-nmf-out-matrix.html">
   Out of matrix non-negative matrix factorisation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tensor_factorization/2017-04-20-parafac-out-tensor.html">
   Out of Tensor factorisation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tensor_factorization/2017-08-13-mf-autograd-adagrad.html">
   Adagrad based matrix factorization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tensor_factorization/2017-04-21-constrained-nmf-cvx.html">
   Constrained Non-negative matrix factorisation using CVXPY
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Neural Networks
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../neural_networks/2020-03-08-keras-neural-non-linear.html">
   Some Neural Network Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../neural_networks/2020-02-28-xor-relu-vector.html">
   Learning neural network for XOR
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../neural_networks/2020-03-02-linear-scratch.html">
   Neural Networks from scratch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../neural_networks/2018-01-13-denoising.html">
   Signal denoising using RNNs in PyTorch
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Expectation Maximization
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../em/2014-06-01-em.html">
   Programatically understanding Expectation Maximization
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Recommender Systems
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Recommender Systems in Keras
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2017-12-29-neural-collaborative-filtering.html">
   Neural Networks for Collaborative Filtering
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Active Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../active_learning/2018-06-20-active-committee.html">
   Active Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../active_learning/2022_01_24_Query_by_Committee.html">
   Query by Committee
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../active_learning/2020-04-21-active-learning-with-bayesian-linear-regression.html">
   Active Learning with Bayesian Linear Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../active_learning/2022-03-06-maximal-expected-error-reduction.html">
   Problem with Expected Model Change
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  JAX
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../jax/introduction-jax.html">
   Using PRNG key
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ml_softwares/2022-02-09-autograd-pytorch-jax.html">
   Autograd in JAX and PyTorch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ml_softwares/2017-08-12-linear-regression-adagrad-vs-gd.html">
   Programatically understanding Adagrad
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Appendix 1 - Linear Algebra for ML
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../appendix_1_-_linear_algebra_for_ml/2021-03-15-eigen.html">
   Eigen values
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../appendix_1_-_linear_algebra_for_ml/2021-03-15-determinant.html">
   Determinant
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../appendix_1_-_linear_algebra_for_ml/2021-03-15-Positive-semi-definite.html">
   Positive definiteness
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../appendix_1_-_linear_algebra_for_ml/2022-02-11-matrix.html">
   Matrix as transformation and interpreting low rank matrix
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Appendix 2 - Stochastic processes
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../appendix_2_-_stochastic_processes/2021-03-19-stochastic-processes.html">
   Stochastic processes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../appendix_2_-_stochastic_processes/2021-03-17-Stationary-Time_Series.html">
   Stationarity of time-series stochastic process
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../appendix_2_-_stochastic_processes/2021-03-23-Stationarity-stochastic-processes.html">
   Stationarity of stochastic processes II
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  References
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../references/references.html">
   References
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/notebooks/recommender_systems/2017-12-18-recommend-keras.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/prog-ml/prog-ml.github.io"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/prog-ml/prog-ml.github.io/issues/new?title=Issue%20on%20page%20%2Fnotebooks/recommender_systems/2017-12-18-recommend-keras.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/prog-ml/prog-ml.github.io/edit/main/notebooks/recommender_systems/2017-12-18-recommend-keras.ipynb"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/prog-ml/prog-ml.github.io/main?urlpath=tree/notebooks/recommender_systems/2017-12-18-recommend-keras.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/prog-ml/prog-ml.github.io/blob/main/notebooks/recommender_systems/2017-12-18-recommend-keras.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        <button type="button" class="btn btn-secondary topbarbtn"
            onclick="initThebeSBT()" title="Launch Thebe" data-toggle="tooltip" data-placement="left"><i
                class="fas fa-play"></i><span style="margin-left: .4em;">Live Code</span></button>
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#task">
   <strong>
    Task
   </strong>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#peak-into-the-dataset">
   Peak into the dataset
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-test-split">
   Train test split
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#matrix-factorisation">
   Matrix factorisation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#matrix-factorisation-in-keras">
   Matrix factorisation in Keras
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#train-error-v-s-epoch-number">
     Train error v/s epoch number
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#prediction-error">
     Prediction error
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#extracting-the-learnt-embeddings">
     Extracting the learnt embeddings
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#non-negative-matrix-factorisation-nnmf-in-keras">
   Non-negative Matrix factorisation (NNMF) in Keras
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#neural-networks-for-recommendation">
   Neural networks for recommendation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#prediction-performance-of-neural-network-based-recommender-system">
     Prediction performance of Neural Network based recommender system
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Recommender Systems in Keras</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#task">
   <strong>
    Task
   </strong>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#peak-into-the-dataset">
   Peak into the dataset
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-test-split">
   Train test split
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#matrix-factorisation">
   Matrix factorisation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#matrix-factorisation-in-keras">
   Matrix factorisation in Keras
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#train-error-v-s-epoch-number">
     Train error v/s epoch number
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#prediction-error">
     Prediction error
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#extracting-the-learnt-embeddings">
     Extracting the learnt embeddings
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#non-negative-matrix-factorisation-nnmf-in-keras">
   Non-negative Matrix factorisation (NNMF) in Keras
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#neural-networks-for-recommendation">
   Neural networks for recommendation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#prediction-performance-of-neural-network-based-recommender-system">
     Prediction performance of Neural Network based recommender system
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="recommender-systems-in-keras">
<h1>Recommender Systems in Keras<a class="headerlink" href="#recommender-systems-in-keras" title="Permalink to this headline">Â¶</a></h1>
<blockquote>
<div><p>A programming introduction to recommender systems using Keras!</p>
</div></blockquote>
<ul class="simple">
<li><p>toc: true</p></li>
<li><p>badges: true</p></li>
<li><p>comments: true</p></li>
<li><p>author: Nipun Batra</p></li>
<li><p>categories: [ML]</p></li>
</ul>
<p>I have written a <span class="xref myst">few</span> <span class="xref myst">posts</span> <span class="xref myst">earlier</span> <span class="xref myst">about</span> <span class="xref myst">matrix</span> <span class="xref myst">factorisation</span> <span class="xref myst">using</span> various Python libraries. The main application I had in mind for matrix factorisation was <a class="reference external" href="https://en.wikipedia.org/wiki/Recommender_system">recommender systems</a>. In this post, Iâ€™ll write about using <a class="reference external" href="https://keras.io">Keras</a> for creating recommender systems. <a class="reference external" href="https://github.com/maciejkula/triplet_recommendations_keras">Various</a> <a class="reference external" href="http://blog.richardweiss.org/2016/09/25/movie-embeddings.html">people</a> <a class="reference external" href="https://github.com/bradleypallen/keras-movielens-cf">have</a> <a class="reference external" href="https://github.com/hexiangnan/neural_collaborative_filtering">written</a> <a class="reference external" href="https://github.com/sonyisme/keras-recommendation">excellent</a> <a class="reference external" href="http://course.fast.ai/lessons/lesson4.html">similar</a> <a class="reference external" href="https://github.com/maciejkula/spotlight">posts</a> and code that I draw a lot of inspiration from, and give them their credit! Iâ€™m assuming that a reader has some experience with Keras, as this post is not intended to be an introduction to Keras.</p>
<p>Specifically, in this post, Iâ€™ll talk about:</p>
<ol class="simple">
<li><p>Matrix Factorisation in Keras</p></li>
<li><p>Adding non-negativitiy constraints to solve non-negative matrix factorisation (NNMF)</p></li>
<li><p>Using neural networks for recommendations</p></li>
</ol>
<p>Iâ€™ll be using the Movielens-100k dataset for illustration. There are 943 users and 1682 movies. In total there are a 100k ratings in the dataset. It should be noted that the max. total number of rating for the &lt;users, movies&gt; would be 943*1682, which means that we have about 7% of the total ratings! All rating are on a scale of 1-5.</p>
<div class="section" id="task">
<h2><strong>Task</strong><a class="headerlink" href="#task" title="Permalink to this headline">Â¶</a></h2>
<p>Given this set of ratings, can we recommend the next set of movies to a user? This would translate to: for every user, estimating the ratings for all the movies that (s)he hasnâ€™t watched and maybe recommend the top-k movies by the esimtated ratings!</p>
</div>
<div class="section" id="peak-into-the-dataset">
<h2>Peak into the dataset<a class="headerlink" href="#peak-into-the-dataset" title="Permalink to this headline">Â¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;/Users/nipun/Downloads/ml-100k/u.data&quot;</span><span class="p">,</span><span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">,</span><span class="n">names</span><span class="o">=</span><span class="s2">&quot;user_id,item_id,rating,timestamp&quot;</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;,&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>user_id</th>
      <th>item_id</th>
      <th>rating</th>
      <th>timestamp</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>196</td>
      <td>242</td>
      <td>3</td>
      <td>881250949</td>
    </tr>
    <tr>
      <th>1</th>
      <td>186</td>
      <td>302</td>
      <td>3</td>
      <td>891717742</td>
    </tr>
    <tr>
      <th>2</th>
      <td>22</td>
      <td>377</td>
      <td>1</td>
      <td>878887116</td>
    </tr>
    <tr>
      <th>3</th>
      <td>244</td>
      <td>51</td>
      <td>2</td>
      <td>880606923</td>
    </tr>
    <tr>
      <th>4</th>
      <td>166</td>
      <td>346</td>
      <td>1</td>
      <td>886397596</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>So, each record (row) shows the rating for a user, item (movie) pair. It should be noted that I use  item and movie interchangeably in this post.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">user_id</span><span class="o">.</span><span class="n">unique</span><span class="p">()),</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">item_id</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(943, 1682)
</pre></div>
</div>
</div>
</div>
<p>We assign a unique number between (0, #users) to each user and do the same for movies.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span><span class="o">.</span><span class="n">user_id</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">user_id</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;category&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">cat</span><span class="o">.</span><span class="n">codes</span><span class="o">.</span><span class="n">values</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">item_id</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">item_id</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;category&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">cat</span><span class="o">.</span><span class="n">codes</span><span class="o">.</span><span class="n">values</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>user_id</th>
      <th>item_id</th>
      <th>rating</th>
      <th>timestamp</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>195</td>
      <td>241</td>
      <td>3</td>
      <td>881250949</td>
    </tr>
    <tr>
      <th>1</th>
      <td>185</td>
      <td>301</td>
      <td>3</td>
      <td>891717742</td>
    </tr>
    <tr>
      <th>2</th>
      <td>21</td>
      <td>376</td>
      <td>1</td>
      <td>878887116</td>
    </tr>
    <tr>
      <th>3</th>
      <td>243</td>
      <td>50</td>
      <td>2</td>
      <td>880606923</td>
    </tr>
    <tr>
      <th>4</th>
      <td>165</td>
      <td>345</td>
      <td>1</td>
      <td>886397596</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="train-test-split">
<h2>Train test split<a class="headerlink" href="#train-test-split" title="Permalink to this headline">Â¶</a></h2>
<p>Weâ€™ll now split our dataset of 100k ratings into train (containing 80k ratings) and test (containing 20k ratings). Given the train set, weâ€™d like to accurately estimate the ratings in the test set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>user_id</th>
      <th>item_id</th>
      <th>rating</th>
      <th>timestamp</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>90092</th>
      <td>832</td>
      <td>12</td>
      <td>2</td>
      <td>875036139</td>
    </tr>
    <tr>
      <th>50879</th>
      <td>94</td>
      <td>132</td>
      <td>3</td>
      <td>888954341</td>
    </tr>
    <tr>
      <th>67994</th>
      <td>436</td>
      <td>12</td>
      <td>4</td>
      <td>880141129</td>
    </tr>
    <tr>
      <th>49769</th>
      <td>710</td>
      <td>344</td>
      <td>4</td>
      <td>884485683</td>
    </tr>
    <tr>
      <th>11032</th>
      <td>121</td>
      <td>736</td>
      <td>4</td>
      <td>879270874</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>user_id</th>
      <th>item_id</th>
      <th>rating</th>
      <th>timestamp</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>89284</th>
      <td>907</td>
      <td>493</td>
      <td>3</td>
      <td>879723046</td>
    </tr>
    <tr>
      <th>60499</th>
      <td>550</td>
      <td>25</td>
      <td>4</td>
      <td>892785056</td>
    </tr>
    <tr>
      <th>11090</th>
      <td>373</td>
      <td>222</td>
      <td>5</td>
      <td>880394520</td>
    </tr>
    <tr>
      <th>36096</th>
      <td>199</td>
      <td>140</td>
      <td>4</td>
      <td>884129346</td>
    </tr>
    <tr>
      <th>21633</th>
      <td>71</td>
      <td>317</td>
      <td>5</td>
      <td>880037702</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="matrix-factorisation">
<h2>Matrix factorisation<a class="headerlink" href="#matrix-factorisation" title="Permalink to this headline">Â¶</a></h2>
<p>One popular recommender systems approach is called Matrix Factorisation. It works on the principle that we can learn a low-dimensional representation (embedding) of user and movie. For example, for each movie, we can have how much action it has, how long it is, and so on. For each user, we can encode how much they like action, or how much they like long movies, etc. Thus, we can combine the user and the movie embeddings to estimate the ratings on unseen movies. This approach can also be viewed as: given a matrix (A [M X N]) containing users and movies, we want to estimate low dimensional matrices (W [M X k] and H [M X k]), such that: <span class="math notranslate nohighlight">\(A \approx W.H^T\)</span></p>
</div>
<div class="section" id="matrix-factorisation-in-keras">
<h2>Matrix factorisation in Keras<a class="headerlink" href="#matrix-factorisation-in-keras" title="Permalink to this headline">Â¶</a></h2>
<p>Weâ€™ll now write some code to solve the recommendation problem by matrix factorisation in Keras. Weâ€™re trying to learn two low-dimensional embeddings of users and items.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">keras</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">SVG</span>
<span class="kn">from</span> <span class="nn">keras.optimizers</span> <span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span> <span class="nn">keras.utils.vis_utils</span> <span class="kn">import</span> <span class="n">model_to_dot</span>
<span class="n">n_users</span><span class="p">,</span> <span class="n">n_movies</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">user_id</span><span class="o">.</span><span class="n">unique</span><span class="p">()),</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">item_id</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
<span class="n">n_latent_factors</span> <span class="o">=</span> <span class="mi">3</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Using TensorFlow backend.
</pre></div>
</div>
</div>
</div>
<p>The key thing is to learn an embedding for movies and users, and then combine them using the dot product! For estimating the rating, for each user, movie pair of interest, weâ€™d take the dot product of the respective user and item embedding. As an example, if we have 2 dimensions in our user and item embedding, which say correspond to [how much user likes action, how much user likes long movies], and the item embedding is [how much action is in the movie, how long is the movie]. Then, we can predict for a user <code class="docutils literal notranslate"><span class="pre">u</span></code>, and movie <code class="docutils literal notranslate"><span class="pre">m</span></code> as how much <code class="docutils literal notranslate"><span class="pre">u</span></code> likes action <span class="math notranslate nohighlight">\(\times\)</span> how much action is there in <code class="docutils literal notranslate"><span class="pre">m</span></code> <span class="math notranslate nohighlight">\(+\)</span> how much <code class="docutils literal notranslate"><span class="pre">u</span></code> likes long movies <span class="math notranslate nohighlight">\(\times\)</span> how long is <code class="docutils literal notranslate"><span class="pre">m</span></code>.</p>
<p>Our model would optimise the emebedding such that we minimise the mean squared error on the ratings from the train set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">movie_input</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;Item&#39;</span><span class="p">)</span>
<span class="n">movie_embedding</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">n_movies</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_latent_factors</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Movie-Embedding&#39;</span><span class="p">)(</span><span class="n">movie_input</span><span class="p">)</span>
<span class="n">movie_vec</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;FlattenMovies&#39;</span><span class="p">)(</span><span class="n">movie_embedding</span><span class="p">)</span>

<span class="n">user_input</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;User&#39;</span><span class="p">)</span>
<span class="n">user_vec</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;FlattenUsers&#39;</span><span class="p">)(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">n_users</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_latent_factors</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;User-Embedding&#39;</span><span class="p">)(</span><span class="n">user_input</span><span class="p">))</span>

<span class="n">prod</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">merge</span><span class="p">([</span><span class="n">movie_vec</span><span class="p">,</span> <span class="n">user_vec</span><span class="p">],</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;dot&#39;</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;DotProduct&#39;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">([</span><span class="n">user_input</span><span class="p">,</span> <span class="n">movie_input</span><span class="p">],</span> <span class="n">prod</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="s1">&#39;mean_squared_error&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Hereâ€™s a visualisation of our model for a better understanding.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">SVG</span><span class="p">(</span><span class="n">model_to_dot</span><span class="p">(</span><span class="n">model</span><span class="p">,</span>  <span class="n">show_shapes</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">show_layer_names</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">rankdir</span><span class="o">=</span><span class="s1">&#39;HB&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">prog</span><span class="o">=</span><span class="s1">&#39;dot&#39;</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s1">&#39;svg&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/2017-12-18-recommend-keras_22_0.svg" src="../../_images/2017-12-18-recommend-keras_22_0.svg" /></div>
</div>
<p>We can see that in the <code class="docutils literal notranslate"><span class="pre">Merge</span></code> layer, we take the dot product of the user and the item embeddings to obtain the rating.</p>
<p>We can also summarise our model as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Item (InputLayer)               (None, 1)            0                                            
__________________________________________________________________________________________________
User (InputLayer)               (None, 1)            0                                            
__________________________________________________________________________________________________
Movie-Embedding (Embedding)     (None, 1, 3)         5049        Item[0][0]                       
__________________________________________________________________________________________________
User-Embedding (Embedding)      (None, 1, 3)         2832        User[0][0]                       
__________________________________________________________________________________________________
FlattenMovies (Flatten)         (None, 3)            0           Movie-Embedding[0][0]            
__________________________________________________________________________________________________
FlattenUsers (Flatten)          (None, 3)            0           User-Embedding[0][0]             
__________________________________________________________________________________________________
DotProduct (Merge)              (None, 1)            0           FlattenMovies[0][0]              
                                                                 FlattenUsers[0][0]               
==================================================================================================
Total params: 7,881
Trainable params: 7,881
Non-trainable params: 0
__________________________________________________________________________________________________
</pre></div>
</div>
</div>
</div>
<p>So, we have 7881 parameters to learn! Letâ€™s train our model now!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">([</span><span class="n">train</span><span class="o">.</span><span class="n">user_id</span><span class="p">,</span> <span class="n">train</span><span class="o">.</span><span class="n">item_id</span><span class="p">],</span> <span class="n">train</span><span class="o">.</span><span class="n">rating</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="train-error-v-s-epoch-number">
<h3>Train error v/s epoch number<a class="headerlink" href="#train-error-v-s-epoch-number" title="Permalink to this headline">Â¶</a></h3>
<p>Before we test how well our model does in the test setting, we can visualise the train loss with epoch number.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">logy</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Train Error&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.text.Text at 0x1155a07b8&gt;
</pre></div>
</div>
<img alt="../../_images/2017-12-18-recommend-keras_29_1.png" src="../../_images/2017-12-18-recommend-keras_29_1.png" />
</div>
</div>
</div>
<div class="section" id="prediction-error">
<h3>Prediction error<a class="headerlink" href="#prediction-error" title="Permalink to this headline">Â¶</a></h3>
<p>Letâ€™s now see how our model does! Iâ€™ll do a small post-processing step to round off our prediction to the nearest integer. This is usually not done, and thus just a whimsical step, since the training ratings are all integers! There are better ways to encode this intger requirement (one-hot encoding!), but we wonâ€™t discuss them in this post.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">([</span><span class="n">test</span><span class="o">.</span><span class="n">user_id</span><span class="p">,</span> <span class="n">test</span><span class="o">.</span><span class="n">item_id</span><span class="p">]),</span><span class="mi">0</span><span class="p">)</span>
<span class="n">y_true</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">rating</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.6915
</pre></div>
</div>
</div>
</div>
<p>Not bad! Weâ€™re able to get a <span class="math notranslate nohighlight">\(MAE\)</span> of 0.69! Iâ€™m sure with a bit of parameter/hyper-parameter optimisation, we may be able to improve the results. However, I wonâ€™t talk about these optimisations in this post.</p>
</div>
<div class="section" id="extracting-the-learnt-embeddings">
<h3>Extracting the learnt embeddings<a class="headerlink" href="#extracting-the-learnt-embeddings" title="Permalink to this headline">Â¶</a></h3>
<p>We can extract the learnt movie and item embeddings as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">movie_embedding_learnt</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_layer</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;Movie-Embedding&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">movie_embedding_learnt</span><span class="p">)</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>1683.000000</td>
      <td>1683.000000</td>
      <td>1683.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>-0.935420</td>
      <td>0.857862</td>
      <td>0.954169</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.517458</td>
      <td>0.447439</td>
      <td>0.458095</td>
    </tr>
    <tr>
      <th>min</th>
      <td>-2.524487</td>
      <td>-0.459752</td>
      <td>-0.989537</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>-1.323431</td>
      <td>0.546364</td>
      <td>0.642444</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>-0.949188</td>
      <td>0.851243</td>
      <td>0.993619</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>-0.550862</td>
      <td>1.159588</td>
      <td>1.283555</td>
    </tr>
    <tr>
      <th>max</th>
      <td>0.500618</td>
      <td>2.140607</td>
      <td>2.683658</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">user_embedding_learnt</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_layer</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;User-Embedding&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">user_embedding_learnt</span><span class="p">)</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>944.000000</td>
      <td>944.000000</td>
      <td>944.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>-1.126231</td>
      <td>1.171609</td>
      <td>1.109131</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.517478</td>
      <td>0.409016</td>
      <td>0.548384</td>
    </tr>
    <tr>
      <th>min</th>
      <td>-2.883226</td>
      <td>-0.500010</td>
      <td>-0.415373</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>-1.458197</td>
      <td>0.903574</td>
      <td>0.735729</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>-1.159480</td>
      <td>1.199517</td>
      <td>1.084089</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>-0.836746</td>
      <td>1.456610</td>
      <td>1.468611</td>
    </tr>
    <tr>
      <th>max</th>
      <td>0.899436</td>
      <td>2.605330</td>
      <td>2.826109</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>We can see that both the user and the item embeddings have negative elements. There are some applications which require that the learnt embeddings be non-negative. This approach is also called non-negative matrix factorisation, which weâ€™ll workout now.</p>
</div>
</div>
<div class="section" id="non-negative-matrix-factorisation-nnmf-in-keras">
<h2>Non-negative Matrix factorisation (NNMF) in Keras<a class="headerlink" href="#non-negative-matrix-factorisation-nnmf-in-keras" title="Permalink to this headline">Â¶</a></h2>
<p>The code for NNMF remains exactly the same as the code for matrix factorisation. The only change is that we add <code class="docutils literal notranslate"><span class="pre">non-negativity</span></code> constraints on the learnt embeddings. This is done as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">keras.constraints</span> <span class="kn">import</span> <span class="n">non_neg</span>
<span class="n">movie_input</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;Item&#39;</span><span class="p">)</span>
<span class="n">movie_embedding</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">n_movies</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_latent_factors</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;NonNegMovie-Embedding&#39;</span><span class="p">,</span> <span class="n">embeddings_constraint</span><span class="o">=</span><span class="n">non_neg</span><span class="p">())(</span><span class="n">movie_input</span><span class="p">)</span>
<span class="n">movie_vec</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;FlattenMovies&#39;</span><span class="p">)(</span><span class="n">movie_embedding</span><span class="p">)</span>

<span class="n">user_input</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;User&#39;</span><span class="p">)</span>
<span class="n">user_vec</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;FlattenUsers&#39;</span><span class="p">)(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">n_users</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_latent_factors</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;NonNegUser-Embedding&#39;</span><span class="p">,</span><span class="n">embeddings_constraint</span><span class="o">=</span><span class="n">non_neg</span><span class="p">())(</span><span class="n">user_input</span><span class="p">))</span>

<span class="n">prod</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">merge</span><span class="p">([</span><span class="n">movie_vec</span><span class="p">,</span> <span class="n">user_vec</span><span class="p">],</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;dot&#39;</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;DotProduct&#39;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">([</span><span class="n">user_input</span><span class="p">,</span> <span class="n">movie_input</span><span class="p">],</span> <span class="n">prod</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="s1">&#39;mean_squared_error&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We now verify if we are indeed able to learn non-negative embeddings. Iâ€™ll not compare the performance of NNMF on the test set, in the interest of space.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">history_nonneg</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">([</span><span class="n">train</span><span class="o">.</span><span class="n">user_id</span><span class="p">,</span> <span class="n">train</span><span class="o">.</span><span class="n">item_id</span><span class="p">],</span> <span class="n">train</span><span class="o">.</span><span class="n">rating</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">movie_embedding_learnt</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_layer</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;NonNegMovie-Embedding&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">movie_embedding_learnt</span><span class="p">)</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>1683.000000</td>
      <td>1683.000000</td>
      <td>1683.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>0.838450</td>
      <td>0.840330</td>
      <td>0.838066</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.301618</td>
      <td>0.301529</td>
      <td>0.301040</td>
    </tr>
    <tr>
      <th>min</th>
      <td>-0.000000</td>
      <td>-0.000000</td>
      <td>-0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>0.657749</td>
      <td>0.663951</td>
      <td>0.656453</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>0.901495</td>
      <td>0.904192</td>
      <td>0.895934</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>1.072706</td>
      <td>1.073591</td>
      <td>1.072926</td>
    </tr>
    <tr>
      <th>max</th>
      <td>1.365719</td>
      <td>1.379006</td>
      <td>1.373672</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Looks good!</p>
</div>
<div class="section" id="neural-networks-for-recommendation">
<h2>Neural networks for recommendation<a class="headerlink" href="#neural-networks-for-recommendation" title="Permalink to this headline">Â¶</a></h2>
<p>Weâ€™ll now create a simple neural network for recommendation, or for estimating rating! This model is very similar to the earlier matrix factorisation models, but differs in the following ways:</p>
<ol class="simple">
<li><p>Instead of taking a dot product of the user and the item embedding, we concatenate them and use them as features for our neural network. Thus, we are not constrained to the dot product way of combining the embeddings, and can learn complex non-linear relationships.</p></li>
<li><p>Due to #1, we can now have a different dimension of user and item embeddings. This can be useful if one dimension is larger than the other.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_latent_factors_user</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">n_latent_factors_movie</span> <span class="o">=</span> <span class="mi">8</span>

<span class="n">movie_input</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;Item&#39;</span><span class="p">)</span>
<span class="n">movie_embedding</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">n_movies</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_latent_factors_movie</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Movie-Embedding&#39;</span><span class="p">)(</span><span class="n">movie_input</span><span class="p">)</span>
<span class="n">movie_vec</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;FlattenMovies&#39;</span><span class="p">)(</span><span class="n">movie_embedding</span><span class="p">)</span>
<span class="n">movie_vec</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)(</span><span class="n">movie_vec</span><span class="p">)</span>


<span class="n">user_input</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;User&#39;</span><span class="p">)</span>
<span class="n">user_vec</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;FlattenUsers&#39;</span><span class="p">)(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">n_users</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_latent_factors_user</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;User-Embedding&#39;</span><span class="p">)(</span><span class="n">user_input</span><span class="p">))</span>
<span class="n">user_vec</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)(</span><span class="n">user_vec</span><span class="p">)</span>


<span class="n">concat</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">merge</span><span class="p">([</span><span class="n">movie_vec</span><span class="p">,</span> <span class="n">user_vec</span><span class="p">],</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;concat&#39;</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;Concat&#39;</span><span class="p">)</span>
<span class="n">concat_dropout</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)(</span><span class="n">concat</span><span class="p">)</span>
<span class="n">dense</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;FullyConnected&#39;</span><span class="p">)(</span><span class="n">concat</span><span class="p">)</span>
<span class="n">dropout_1</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;Dropout&#39;</span><span class="p">)(</span><span class="n">dense</span><span class="p">)</span>
<span class="n">dense_2</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;FullyConnected-1&#39;</span><span class="p">)(</span><span class="n">concat</span><span class="p">)</span>
<span class="n">dropout_2</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;Dropout&#39;</span><span class="p">)(</span><span class="n">dense_2</span><span class="p">)</span>
<span class="n">dense_3</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;FullyConnected-2&#39;</span><span class="p">)(</span><span class="n">dense_2</span><span class="p">)</span>
<span class="n">dropout_3</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;Dropout&#39;</span><span class="p">)(</span><span class="n">dense_3</span><span class="p">)</span>
<span class="n">dense_4</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;FullyConnected-3&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">dense_3</span><span class="p">)</span>


<span class="n">result</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;Activation&#39;</span><span class="p">)(</span><span class="n">dense_4</span><span class="p">)</span>
<span class="n">adam</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.005</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">([</span><span class="n">user_input</span><span class="p">,</span> <span class="n">movie_input</span><span class="p">],</span> <span class="n">result</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">adam</span><span class="p">,</span><span class="n">loss</span><span class="o">=</span> <span class="s1">&#39;mean_absolute_error&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Letâ€™s now see how our model looks like:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">SVG</span><span class="p">(</span><span class="n">model_to_dot</span><span class="p">(</span><span class="n">model</span><span class="p">,</span>  <span class="n">show_shapes</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">show_layer_names</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">rankdir</span><span class="o">=</span><span class="s1">&#39;HB&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">prog</span><span class="o">=</span><span class="s1">&#39;dot&#39;</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s1">&#39;svg&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/2017-12-18-recommend-keras_50_0.svg" src="../../_images/2017-12-18-recommend-keras_50_0.svg" /></div>
</div>
<p>It should be noted that we use a different number of embeddings for user (3) and items (5)! These combine to form a vector of length (5+3 = 8), which is then fed into the neural network. We also add a dropout layer to prevent overfitting!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Item (InputLayer)               (None, 1)            0                                            
__________________________________________________________________________________________________
User (InputLayer)               (None, 1)            0                                            
__________________________________________________________________________________________________
Movie-Embedding (Embedding)     (None, 1, 8)         13464       Item[0][0]                       
__________________________________________________________________________________________________
User-Embedding (Embedding)      (None, 1, 5)         4720        User[0][0]                       
__________________________________________________________________________________________________
FlattenMovies (Flatten)         (None, 8)            0           Movie-Embedding[0][0]            
__________________________________________________________________________________________________
FlattenUsers (Flatten)          (None, 5)            0           User-Embedding[0][0]             
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 8)            0           FlattenMovies[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 5)            0           FlattenUsers[0][0]               
__________________________________________________________________________________________________
Concat (Merge)                  (None, 13)           0           dropout_1[0][0]                  
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
FullyConnected-1 (Dense)        (None, 100)          1400        Concat[0][0]                     
__________________________________________________________________________________________________
FullyConnected-2 (Dense)        (None, 50)           5050        FullyConnected-1[0][0]           
__________________________________________________________________________________________________
FullyConnected-3 (Dense)        (None, 20)           1020        FullyConnected-2[0][0]           
__________________________________________________________________________________________________
Activation (Dense)              (None, 1)            21          FullyConnected-3[0][0]           
==================================================================================================
Total params: 25,675
Trainable params: 25,675
Non-trainable params: 0
__________________________________________________________________________________________________
</pre></div>
</div>
</div>
</div>
<p>We can see that the number of parameters is more than what we had in the Matrix Factorisation case. Letâ€™s see how this model works. Iâ€™ll run it for more epochs given that we have more parameters.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">([</span><span class="n">train</span><span class="o">.</span><span class="n">user_id</span><span class="p">,</span> <span class="n">train</span><span class="o">.</span><span class="n">item_id</span><span class="p">],</span> <span class="n">train</span><span class="o">.</span><span class="n">rating</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="prediction-performance-of-neural-network-based-recommender-system">
<h3>Prediction performance of Neural Network based recommender system<a class="headerlink" href="#prediction-performance-of-neural-network-based-recommender-system" title="Permalink to this headline">Â¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_hat_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">([</span><span class="n">test</span><span class="o">.</span><span class="n">user_id</span><span class="p">,</span> <span class="n">test</span><span class="o">.</span><span class="n">item_id</span><span class="p">]),</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_hat_2</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">([</span><span class="n">test</span><span class="o">.</span><span class="n">user_id</span><span class="p">,</span> <span class="n">test</span><span class="o">.</span><span class="n">item_id</span><span class="p">])))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.6957
0.708807692927
</pre></div>
</div>
</div>
</div>
<p>Pretty similar to the result we got using matrix factorisation. Maybe, we need to tweak around a lot more with the neural network to get better results?</p>
<p>Thanks for reading. This post has been a good learning experience for me. Hope you enjoyed too!</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "prog-ml/prog-ml.github.io",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./notebooks/recommender_systems"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="../em/2014-06-01-em.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Programatically understanding Expectation Maximization</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="2017-12-29-neural-collaborative-filtering.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Neural Networks for Collaborative Filtering</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By The Jupyter Book community<br/>
    
        &copy; Copyright 2022.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>