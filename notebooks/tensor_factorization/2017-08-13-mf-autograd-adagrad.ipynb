{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Adagrad based matrix factorization\n",
    "> Adagrad optimizer for matrix factorisation\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Nipun Batra\n",
    "- categories: [ML]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a [previous post](./nnmf-tensorflow.html), we had seen how to perfom non-negative matrix factorization (NNMF) using Tensorflow. In [another previous post](./linear-regression-adagrad-vs-gd.html), I had shown how to use Adagrad for linear regression. This current post can be considered an extension of the linear regression using Adagrad post. Just for the purpose of education, I'll poorly initialise the estimate of one of the decomposed matrix, to see how well Adagrad can adjust weights!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib import gridspec\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the matrix to be decomposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = np.array([[3, 4, 5, 2],\n",
    "                   [4, 4, 3, 3],\n",
    "                   [5, 5, 4, 3]], dtype=np.float32).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masking one entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A[0, 0] = np.NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ nan,   4.,   5.],\n",
       "       [  4.,   4.,   5.],\n",
       "       [  5.,   3.,   4.],\n",
       "       [  2.,   3.,   3.]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost(param_list):\n",
    "    W, H = param_list\n",
    "    pred = np.dot(W, H)\n",
    "    mask = ~np.isnan(A)\n",
    "    return np.sqrt(((pred - A)[mask].flatten() ** 2).mean(axis=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposition params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rank = 2\n",
    "learning_rate=0.01\n",
    "n_steps = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Adagrad routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adagrad_gd(param_init, cost, niter=5, lr=1e-2, eps=1e-8, random_seed=0):\n",
    "    \"\"\"\n",
    "    param_init: List of initial values of parameters\n",
    "    cost: cost function\n",
    "    niter: Number of iterations to run\n",
    "    lr: Learning rate\n",
    "    eps: Fudge factor, to avoid division by zero\n",
    "    \"\"\"\n",
    "    from copy import deepcopy\n",
    "    from autograd import grad\n",
    "    # Fixing the random_seed\n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "    # Function to compute the gradient of the cost function\n",
    "    grad_cost = grad(cost)\n",
    "    params = deepcopy(param_init)\n",
    "    param_array, grad_array, lr_array, cost_array = [params], [], [[lr*np.ones_like(_) for _ in params]], [cost(params)]\n",
    "    # Initialising sum of squares of gradients for each param as 0\n",
    "    sum_squares_gradients = [np.zeros_like(param) for param in params]\n",
    "    for i in range(niter):\n",
    "        out_params = []\n",
    "        gradients = grad_cost(params)\n",
    "        # At each iteration, we add the square of the gradients to `sum_squares_gradients`\n",
    "        sum_squares_gradients= [eps + sum_prev + np.square(g) for sum_prev, g in zip(sum_squares_gradients, gradients)]\n",
    "        # Adapted learning rate for parameter list\n",
    "        lrs = [np.divide(lr, np.sqrt(sg)) for sg in sum_squares_gradients]\n",
    "        # Paramter update\n",
    "        params = [param-(adapted_lr*grad_param) for param, adapted_lr, grad_param in zip(params, lrs, gradients)]\n",
    "        param_array.append(params)\n",
    "        lr_array.append(lrs)\n",
    "        grad_array.append(gradients)\n",
    "        cost_array.append(cost(params))\n",
    "        \n",
    "    return params, param_array, grad_array, lr_array, cost_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Adagrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixing initial parameters\n",
    "\n",
    "I'm poorly initialising `H` here to see how the learning rates vary for `W` and `H`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "shape = A.shape\n",
    "H_init =  -5*np.abs(np.random.randn(rank, shape[1]))\n",
    "W_init =  np.abs(np.random.randn(shape[0], rank))\n",
    "param_init = [W_init, H_init]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -8.82026173,  -2.00078604,  -4.89368992],\n",
       "       [-11.204466  ,  -9.33778995,  -4.8863894 ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.95008842,  0.15135721],\n",
       "       [ 0.10321885,  0.4105985 ],\n",
       "       [ 0.14404357,  1.45427351],\n",
       "       [ 0.76103773,  0.12167502]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.651268820608442"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cost for initial set of parameters\n",
    "cost(param_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "eps=1e-8\n",
    "niter=2000\n",
    "ada_params, ada_param_array, ada_grad_array, ada_lr_array, ada_cost_array = adagrad_gd(param_init, cost, niter=niter, lr=lr, eps=eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cost v/s # iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x10ece7610>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEFCAYAAAAi1toCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ed03690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(ada_cost_array).plot(logy=True)\n",
    "plt.ylabel(\"Cost (log scale)\")\n",
    "plt.xlabel(\"# Iterations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final set of parameters and recovered matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  5.0  4.0  5.0\n",
       "1  4.0  4.0  5.0\n",
       "2  5.0  3.0  4.0\n",
       "3  2.0  3.0  3.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_final, H_final = ada_params\n",
    "pred = np.dot(W_final, H_final)\n",
    "pred_df = pd.DataFrame(pred).round()\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Learning rate evolution for W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_lrs = np.array(ada_lr_array)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_lrs = np.array(ada_lr_array)[:, 0]\n",
    "fig= plt.figure(figsize=(4, 2))\n",
    "gs = gridspec.GridSpec(1, 2, width_ratios=[8, 1]) \n",
    "ax = plt.subplot(gs[0]),  plt.subplot(gs[1])\n",
    "max_W, min_W = np.max([np.max(x) for x in W_lrs]), np.min([np.min(x) for x in W_lrs])\n",
    "\n",
    "def update(iteration):\n",
    "    ax[0].cla()\n",
    "    ax[1].cla()\n",
    "    sns.heatmap(W_lrs[iteration], vmin=min_W, vmax=max_W, ax=ax[0], annot=True, fmt='.4f', cbar_ax=ax[1])\n",
    "    ax[0].set_title(\"Learning rate update for W\\nIteration: {}\".format(iteration))\n",
    "    fig.tight_layout()\n",
    "\n",
    "anim = FuncAnimation(fig, update, frames=np.arange(0, 200, 10), interval=500)\n",
    "anim.save('W_update.gif', dpi=80, writer='imagemagick')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://nipunbatra.github.io/blog/images/W_update.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning rate evolution for H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "H_lrs = np.array(ada_lr_array)[:, 1]\n",
    "\n",
    "fig= plt.figure(figsize=(4, 2))\n",
    "gs = gridspec.GridSpec(1, 2, width_ratios=[10, 1]) \n",
    "ax = plt.subplot(gs[0]),  plt.subplot(gs[1])\n",
    "max_H, min_H = np.max([np.max(x) for x in H_lrs]), np.min([np.min(x) for x in H_lrs])\n",
    "\n",
    "def update(iteration):\n",
    "    ax[0].cla()\n",
    "    ax[1].cla()\n",
    "    sns.heatmap(H_lrs[iteration], vmin=min_H, vmax=max_H, ax=ax[0], annot=True, fmt='.2f', cbar_ax=ax[1])\n",
    "    ax[0].set_title(\"Learning rate update for H\\nIteration: {}\".format(iteration))\n",
    "    fig.tight_layout()\n",
    "\n",
    "anim = FuncAnimation(fig, update, frames=np.arange(0, 200, 10), interval=500)\n",
    "anim.save('H_update.gif', dpi=80, writer='imagemagick')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://nipunbatra.github.io/blog/images/H_update.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
